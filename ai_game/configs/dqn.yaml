env:
  width: 20
  height: 20
  seed: 42
  step_penalty: -0.01
  food_reward: 10.0
  death_penalty: -10.0
  shaping_scale: 0.1
  reward_shaping: true
  max_steps_without_food_factor: 100
  block_size: 20

agent:
  state_size: 11
  action_size: 3
  hidden_size: 128
  gamma: 0.99
  lr: 0.001
  batch_size: 128
  buffer_size: 50000
  min_buffer_size: 1000
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay: 0.995
  target_update_every: 20
  seed: 42

train:
  episodes: 800
  max_steps_per_episode: 2000
  log_interval: 20
  checkpoint_interval: 100
  output_dir: outputs
  # device: cpu
